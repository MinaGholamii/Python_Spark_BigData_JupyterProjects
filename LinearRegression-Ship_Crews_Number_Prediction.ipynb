{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f27a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/05 19:15:54 WARN Utils: Your hostname, mina-VirtualBox resolves to a loopback address: 127.0.1.1; using 192.168.1.143 instead (on interface enp0s3)\n",
      "23/09/05 19:15:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/05 19:15:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Import the findspark module and initialize it with the specified Spark path\n",
    "import findspark\n",
    "findspark.init('/home/mina/python-spark/spark-3.4.0-bin-hadoop3/')\n",
    "\n",
    "#Import the pyspark module and the SparkSession class\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create a Spark session with the specified app name\n",
    "spark = SparkSession.builder.appName('ship').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fde882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read a CSV file named 'cruise_ship_info.csv' into a DataFrame\n",
    "#The 'inferSchema=True' option infers data types for columns, and 'header=True' treats the first row as column names\n",
    "dataset = spark.read.csv('cruise_ship_info.csv', inferSchema=True, header=True)\n",
    "\n",
    "#Print the schema of the dataset\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f213d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55),\n",
       " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55),\n",
       " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve and display the first 3 rows of the dataset\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c773c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55) \n",
      "\n",
      "Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55) \n",
      "\n",
      "Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Iterate over the first 3 rows of the dataset and print each row to underestand that cruise lines may have an effect on how many crew memebers we need\n",
    "for record in dataset.head(3):\n",
    "    print(record , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33b1434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|      Cruise_line|count|\n",
      "+-----------------+-----+\n",
      "|            Costa|   11|\n",
      "|              P&O|    6|\n",
      "|           Cunard|    3|\n",
      "|Regent_Seven_Seas|    5|\n",
      "|              MSC|    8|\n",
      "|         Carnival|   22|\n",
      "|          Crystal|    2|\n",
      "|           Orient|    1|\n",
      "|         Princess|   17|\n",
      "|        Silversea|    4|\n",
      "|         Seabourn|    3|\n",
      "| Holland_American|   14|\n",
      "|         Windstar|    3|\n",
      "|           Disney|    2|\n",
      "|        Norwegian|   13|\n",
      "|          Oceania|    3|\n",
      "|          Azamara|    2|\n",
      "|        Celebrity|   10|\n",
      "|             Star|    6|\n",
      "|  Royal_Caribbean|   23|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Group the DataSet by the 'Cruise_line' column, count cruise line we have in dataset\n",
    "#Some of Cruise_line is more important than others\n",
    "dataset.groupBy('Cruise_line').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15263202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, Cruise_line_Indexed=16.0),\n",
       " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, Cruise_line_Indexed=16.0),\n",
       " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, Cruise_line_Indexed=1.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary module for string indexing\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create a StringIndexer transformer to index the 'Cruise_line' column\n",
    "indexer = StringIndexer(inputCol=\"Cruise_line\" , outputCol=\"Cruise_line_Indexed\")\n",
    "\n",
    "# Fit the indexer model to the dataset to generate an indexing model\n",
    "indexerModel = indexer.fit(dataset)\n",
    "\n",
    "# Transform the dataset using the indexing model to add the indexed column\n",
    "index_df = indexerModel.transform(dataset)\n",
    "\n",
    "# Display the first 3 rows of the DataFrame after string indexing\n",
    "index_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa5dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      " |-- Cruise_line_Indexed: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the schema of the DataFrame after string indexing\n",
    "index_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c69098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name',\n",
       " 'Cruise_line',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density',\n",
       " 'crew',\n",
       " 'Cruise_line_Indexed']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrieve and display the column names of the DataFrame after string indexing\n",
    "index_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4af91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, Cruise_line_Indexed=16.0, ShipFeatures=DenseVector([16.0, 6.0, 30.277, 6.94, 5.94, 3.55, 42.64]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the necessary modules for creating feature vectors and vector assembly\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#Create a VectorAssembler to assemble selected columns into a feature vector\n",
    "assembler = VectorAssembler(inputCols=['Cruise_line_Indexed',\n",
    " 'Age',\n",
    " 'Tonnage',\n",
    " 'passengers',\n",
    " 'length',\n",
    " 'cabins',\n",
    " 'passenger_density'] , outputCol='ShipFeatures')\n",
    "\n",
    "# Transform the DataFrame using the VectorAssembler to add the 'ShipFeatures' column\n",
    "output = assembler.transform(index_df)\n",
    "\n",
    "# Display the first row of the transformed DataFrame\n",
    "output.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88fffa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|        shipFeatures|crew|\n",
      "+--------------------+----+\n",
      "|[16.0,6.0,30.2769...|3.55|\n",
      "|[16.0,6.0,30.2769...|3.55|\n",
      "|[1.0,26.0,47.262,...| 6.7|\n",
      "|[1.0,11.0,110.0,2...|19.1|\n",
      "|[1.0,17.0,101.353...|10.0|\n",
      "|[1.0,22.0,70.367,...| 9.2|\n",
      "|[1.0,15.0,70.367,...| 9.2|\n",
      "|[1.0,23.0,70.367,...| 9.2|\n",
      "|[1.0,19.0,70.367,...| 9.2|\n",
      "|[1.0,6.0,110.2389...|11.5|\n",
      "|[1.0,10.0,110.0,2...|11.6|\n",
      "|[1.0,28.0,46.052,...| 6.6|\n",
      "|[1.0,18.0,70.367,...| 9.2|\n",
      "|[1.0,17.0,70.367,...| 9.2|\n",
      "|[1.0,11.0,86.0,21...| 9.3|\n",
      "|[1.0,8.0,110.0,29...|11.6|\n",
      "|[1.0,9.0,88.5,21....|10.3|\n",
      "|[1.0,15.0,70.367,...| 9.2|\n",
      "|[1.0,12.0,88.5,21...| 9.3|\n",
      "|[1.0,20.0,70.367,...| 9.2|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the 'shipFeatures' and 'crew' columns from the transformed DataFrame\n",
    "final_data = output.select('shipFeatures', 'crew')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34914567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              crew|\n",
      "+-------+------------------+\n",
      "|  count|               113|\n",
      "|   mean|7.3488495575221275|\n",
      "| stddev|  3.53108182335618|\n",
      "|    min|              0.59|\n",
      "|    max|              21.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the final_data DataFrame into training and testing datasets\n",
    "# using a split ratio of 70% for training data and 30% for testing data\n",
    "train_data, test_data = final_data.randomSplit([0.7,0.3])\n",
    "\n",
    "# Display summary statistics of the 'train_data' DataFrame\n",
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fd873e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             crew|\n",
      "+-------+-----------------+\n",
      "|  count|               45|\n",
      "|   mean|8.912444444444443|\n",
      "| stddev|3.204840199927401|\n",
      "|    min|             2.95|\n",
      "|    max|             19.1|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics of the 'test_data' DataFrame\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad3340b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/05 19:16:22 WARN Instrumentation: [4ef59c7f] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/09/05 19:16:22 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/09/05 19:16:22 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|-0.12333703160351028|\n",
      "| -0.4925928124001224|\n",
      "|-0.26739893388318414|\n",
      "|-0.36291053314678834|\n",
      "|  -0.864646619368191|\n",
      "|-0.15842213241039538|\n",
      "| -0.6657360918058419|\n",
      "|  0.8552999933277583|\n",
      "|    7.32059685514821|\n",
      "|  0.9038613970524683|\n",
      "|  0.6660277569431283|\n",
      "|  0.7229679964203051|\n",
      "|   0.745410000102277|\n",
      "|   0.748778828937235|\n",
      "|  0.5417925426980599|\n",
      "|  0.6253028634854267|\n",
      "|-0.27141733840355364|\n",
      "|  0.5739443040149403|\n",
      "|  1.2758854260674308|\n",
      "| 0.05015071570874419|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary module for linear regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Create a LinearRegression model with specified features, label, and prediction columns\n",
    "lr = LinearRegression(featuresCol='shipFeatures', labelCol='crew', predictionCol='CrewNumber')\n",
    "\n",
    "# Fit the LinearRegression model to the training data\n",
    "lrModel = lr.fit(train_data)\n",
    "\n",
    "# Evaluate the model on the test data and store the results\n",
    "test_result = lrModel.evaluate(test_data)\n",
    "\n",
    "# Display the residuals (differences between predicted and actual values) of the model on the test data\n",
    "test_result.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f980261b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2426558267325685"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access and display the root mean squared error (RMSE) from the test_result\n",
    "test_result.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e3c4b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8462380778994832"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access and display the R-squared (coefficient of determination) from the test_result\n",
    "test_result.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240976d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             crew|\n",
      "+-------+-----------------+\n",
      "|  count|              158|\n",
      "|   mean|7.794177215189873|\n",
      "| stddev|3.503486564627034|\n",
      "|    min|             0.59|\n",
      "|    max|             21.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics of the 'final_data' DataFrame\n",
    "final_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c00cadba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|corr(crew, passengers)|\n",
      "+----------------------+\n",
      "|    0.9152341306065384|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "# Calculate and display the correlation between 'crew' and 'passengers' columns from main dataset\n",
    "dataset.select(corr('crew' , 'passengers')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a0f084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|corr(crew, cabins)|\n",
      "+------------------+\n",
      "|0.9508226063578497|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the correlation between 'crew' and 'cabins' columns from main dataset\n",
    "dataset.select(corr('crew' , 'cabins')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10137395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088c93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
