{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f27a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyundai Heavy Industries is one of the world's largest ship manufacturing companies and \n",
    "# builds cruise liners. In this project I want to build a predictive model(regression model)\n",
    "# that will help this company to predict how many crew members will be needed for future ships. \n",
    "\n",
    "# Here is what the data looks like so far:\n",
    "\n",
    "# Description: Measurements of ship size, capacity, crew, and age for 158 cruise\n",
    "# ships.\n",
    "\n",
    "# Variables/Columns\n",
    "# Ship Name     1-20\n",
    "# Cruise Line   21-40\n",
    "# Age (as of 2013)   46-48\n",
    "# Tonnage (1000s of tons)   50-56\n",
    "# passengers (100s)   58-64\n",
    "# Length (100s of feet)  66-72\n",
    "# Cabins  (100s)   74-80\n",
    "# Passenger Density   82-88\n",
    "# Crew  (100s)   90-96\n",
    "\n",
    "# It is saved in a csv file for you called \"cruise_ship_info.csv\". \n",
    "\n",
    "# The client also mentioned that they have found that particular cruise lines will differ in \n",
    "# acceptable crew counts, so it is most likely an important feature to include in my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9374580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the findspark module and initialize it with the specified Spark path\n",
    "import findspark\n",
    "findspark.init('/home/mina/python-spark/spark-3.4.0-bin-hadoop3/')\n",
    "\n",
    "#Import the pyspark module and the SparkSession class\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create a Spark session with the specified app name\n",
    "spark = SparkSession.builder.appName('Ship_Project').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "11fde882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read a CSV file named 'cruise_ship_info.csv' into a DataFrame\n",
    "#The 'inferSchema=True' option infers data types for columns, and 'header=True' treats the first row as column names\n",
    "dataset = spark.read.csv('cruise_ship_info.csv', inferSchema=True, header=True)\n",
    "\n",
    "#Print the schema of the dataset\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f213d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55),\n",
       " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55),\n",
       " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve and display the first 3 rows of the dataset\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79c773c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55) \n",
      "\n",
      "Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55) \n",
      "\n",
      "Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Iterate over the first 3 rows of the dataset and print each row to underestand that cruise lines may have an effect on how many crew memebers we need\n",
    "for record in dataset.head(3):\n",
    "    print(record , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f33b1434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|      Cruise_line|count|\n",
      "+-----------------+-----+\n",
      "|            Costa|   11|\n",
      "|              P&O|    6|\n",
      "|           Cunard|    3|\n",
      "|Regent_Seven_Seas|    5|\n",
      "|              MSC|    8|\n",
      "|         Carnival|   22|\n",
      "|          Crystal|    2|\n",
      "|           Orient|    1|\n",
      "|         Princess|   17|\n",
      "|        Silversea|    4|\n",
      "|         Seabourn|    3|\n",
      "| Holland_American|   14|\n",
      "|         Windstar|    3|\n",
      "|           Disney|    2|\n",
      "|        Norwegian|   13|\n",
      "|          Oceania|    3|\n",
      "|          Azamara|    2|\n",
      "|        Celebrity|   10|\n",
      "|             Star|    6|\n",
      "|  Royal_Caribbean|   23|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Group the DataSet by the 'Cruise_line' column, count cruise line we have in dataset\n",
    "#Some of Cruise_line is more important than others\n",
    "dataset.groupBy('Cruise_line').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15263202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, Cruise_line_Indexed=16.0),\n",
       " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, Cruise_line_Indexed=16.0),\n",
       " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, Cruise_line_Indexed=1.0)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary module for string indexing\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create a StringIndexer transformer to index the 'Cruise_line' column\n",
    "indexer = StringIndexer(inputCol=\"Cruise_line\" , outputCol=\"Cruise_line_Indexed\")\n",
    "\n",
    "# Fit the indexer model to the dataset to generate an indexing model\n",
    "indexerModel = indexer.fit(dataset)\n",
    "\n",
    "# Transform the dataset using the indexing model to add the indexed column\n",
    "index_df = indexerModel.transform(dataset)\n",
    "\n",
    "# Display the first 3 rows of the DataFrame after string indexing\n",
    "index_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fa5dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      " |-- Cruise_line_Indexed: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the schema of the DataFrame after string indexing\n",
    "index_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4c69098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ship_name',\n",
       " 'Cruise_line',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density',\n",
       " 'crew',\n",
       " 'Cruise_line_Indexed']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retrieve and display the column names of the DataFrame after string indexing\n",
    "index_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d4af91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, Cruise_line_Indexed=16.0, ShipFeatures=DenseVector([16.0, 6.0, 30.277, 6.94, 5.94, 3.55, 42.64]))]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the necessary modules for creating feature vectors and vector assembly\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#Create a VectorAssembler to assemble selected columns into a feature vector\n",
    "assembler = VectorAssembler(inputCols=['Cruise_line_Indexed',\n",
    " 'Age',\n",
    " 'Tonnage',\n",
    " 'passengers',\n",
    " 'length',\n",
    " 'cabins',\n",
    " 'passenger_density'] , outputCol='ShipFeatures')\n",
    "\n",
    "# Transform the DataFrame using the VectorAssembler to add the 'ShipFeatures' column\n",
    "output = assembler.transform(index_df)\n",
    "\n",
    "# Display the first row of the transformed DataFrame\n",
    "output.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88fffa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|        ShipFeatures|crew|\n",
      "+--------------------+----+\n",
      "|[16.0,6.0,30.2769...|3.55|\n",
      "|[16.0,6.0,30.2769...|3.55|\n",
      "|[1.0,26.0,47.262,...| 6.7|\n",
      "|[1.0,11.0,110.0,2...|19.1|\n",
      "|[1.0,17.0,101.353...|10.0|\n",
      "|[1.0,22.0,70.367,...| 9.2|\n",
      "|[1.0,15.0,70.367,...| 9.2|\n",
      "|[1.0,23.0,70.367,...| 9.2|\n",
      "|[1.0,19.0,70.367,...| 9.2|\n",
      "|[1.0,6.0,110.2389...|11.5|\n",
      "|[1.0,10.0,110.0,2...|11.6|\n",
      "|[1.0,28.0,46.052,...| 6.6|\n",
      "|[1.0,18.0,70.367,...| 9.2|\n",
      "|[1.0,17.0,70.367,...| 9.2|\n",
      "|[1.0,11.0,86.0,21...| 9.3|\n",
      "|[1.0,8.0,110.0,29...|11.6|\n",
      "|[1.0,9.0,88.5,21....|10.3|\n",
      "|[1.0,15.0,70.367,...| 9.2|\n",
      "|[1.0,12.0,88.5,21...| 9.3|\n",
      "|[1.0,20.0,70.367,...| 9.2|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the 'shipFeatures' and 'crew' columns from the transformed DataFrame\n",
    "final_data = output.select('ShipFeatures', 'crew')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "34914567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              crew|\n",
      "+-------+------------------+\n",
      "|  count|               114|\n",
      "|   mean| 7.720175438596498|\n",
      "| stddev|3.5519472367264604|\n",
      "|    min|              0.59|\n",
      "|    max|              21.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the final_data DataFrame into training and testing datasets\n",
    "# using a split ratio of 70% for training data and 30% for testing data\n",
    "train_data, test_data = final_data.randomSplit([0.7,0.3])\n",
    "\n",
    "# Display summary statistics of the 'train_data' DataFrame\n",
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5fd873e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              crew|\n",
      "+-------+------------------+\n",
      "|  count|                44|\n",
      "|   mean|  7.98590909090909|\n",
      "| stddev|3.4072312418926574|\n",
      "|    min|               1.6|\n",
      "|    max|              13.6|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics of the 'test_data' DataFrame\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad3340b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/09 23:42:42 WARN Instrumentation: [af5442bb] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "| -1.2832082087000796|\n",
      "|-0.36674477869317634|\n",
      "| -0.4413874136254563|\n",
      "| -1.0747619492568568|\n",
      "| -0.6190580038826088|\n",
      "| -0.6364773220564572|\n",
      "|  0.6786807107614177|\n",
      "| -0.5857625919210161|\n",
      "| -1.1443710253007975|\n",
      "|  0.5566916941008877|\n",
      "|  0.6197398016191507|\n",
      "| 0.04062398005324397|\n",
      "|  1.1025267634927687|\n",
      "|  1.1025267634927687|\n",
      "| -0.1298853897840999|\n",
      "|  0.9850380555621587|\n",
      "|  0.2774362107835606|\n",
      "| 0.19201677490648983|\n",
      "|  0.5590047345969484|\n",
      "| -0.4167243653939874|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary module for linear regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Create a LinearRegression model with specified features, label, and prediction columns\n",
    "lr = LinearRegression(featuresCol='ShipFeatures', labelCol='crew', predictionCol='CrewNumber')\n",
    "\n",
    "# Fit the LinearRegression model to the training data\n",
    "lrModel = lr.fit(train_data)\n",
    "\n",
    "# Evaluate the model on the test data and store the results\n",
    "test_result = lrModel.evaluate(test_data)\n",
    "\n",
    "# Display the residuals (differences between predicted and actual values) of the model on the test data\n",
    "test_result.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f980261b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636474247531375"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access and display the root mean squared error (RMSE) from the test_result\n",
    "test_result.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e3c4b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9485995660633993"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access and display the R-squared (coefficient of determination) from the test_result\n",
    "test_result.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "240976d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             crew|\n",
      "+-------+-----------------+\n",
      "|  count|              158|\n",
      "|   mean|7.794177215189873|\n",
      "| stddev|3.503486564627034|\n",
      "|    min|             0.59|\n",
      "|    max|             21.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics of the 'final_data' DataFrame\n",
    "final_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c00cadba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|corr(crew, passengers)|\n",
      "+----------------------+\n",
      "|    0.9152341306065384|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "# Calculate and display the correlation between 'crew' and 'passengers' columns from main dataset\n",
    "dataset.select(corr('crew' , 'passengers')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a0f084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|corr(crew, cabins)|\n",
      "+------------------+\n",
      "|0.9508226063578497|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the correlation between 'crew' and 'cabins' columns from main dataset\n",
    "dataset.select(corr('crew' , 'cabins')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
