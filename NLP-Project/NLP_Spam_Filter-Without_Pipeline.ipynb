{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41095531",
   "metadata": {},
   "source": [
    "<h1>Build a Spam Detection Filter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c2b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/18 10:32:18 WARN Utils: Your hostname, mina-VirtualBox resolves to a loopback address: 127.0.1.1; using 192.168.1.143 instead (on interface enp0s3)\n",
      "23/09/18 10:32:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/18 10:32:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "|spam|FreeMsg Hey there...|\n",
      "| ham|Even my brother i...|\n",
      "| ham|As per your reque...|\n",
      "|spam|WINNER!! As a val...|\n",
      "|spam|Had your mobile 1...|\n",
      "| ham|I'm gonna be home...|\n",
      "|spam|SIX chances to wi...|\n",
      "|spam|URGENT! You have ...|\n",
      "| ham|I've been searchi...|\n",
      "| ham|I HAVE A DATE ON ...|\n",
      "|spam|XXXMobileMovieClu...|\n",
      "| ham|Oh k...i'm watchi...|\n",
      "| ham|Eh u remember how...|\n",
      "| ham|Fine if thats th...|\n",
      "|spam|England v Macedon...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the findspark library to locate Spark installation\n",
    "import findspark\n",
    "\n",
    "# Initialize Spark with the specified Spark installation path\n",
    "findspark.init('/home/mina/python-spark/spark-3.4.0-bin-hadoop3/')\n",
    "\n",
    "\n",
    "# Import the pyspark library\n",
    "import pyspark\n",
    "\n",
    "# Import the SparkSession class from pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session with the name 'NLP_Project'\n",
    "spark = SparkSession.builder.appName('NLP_Project').getOrCreate()\n",
    "\n",
    "# Read a CSV file ('smsspamcollection/SMSSpamCollection') into a DataFrame,\n",
    "# inferring the schema from the data, and specifying the tab ('\\t') as the separator\n",
    "data = spark.read.csv('smsspamcollection/SMSSpamCollection', inferSchema = True , sep ='\\t')\n",
    "\n",
    "# Display the contents of the DataFrame\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1c64a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "|  ham|I'm gonna be home...|\n",
      "| spam|SIX chances to wi...|\n",
      "| spam|URGENT! You have ...|\n",
      "|  ham|I've been searchi...|\n",
      "|  ham|I HAVE A DATE ON ...|\n",
      "| spam|XXXMobileMovieClu...|\n",
      "|  ham|Oh k...i'm watchi...|\n",
      "|  ham|Eh u remember how...|\n",
      "|  ham|Fine if thats th...|\n",
      "| spam|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename the '_c0' column to 'class' and '_c1' column to 'text' in the DataFrame 'data'\n",
    "data_main = data.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')\n",
    "\n",
    "# Display the contents of the DataFrame 'data_main'\n",
    "data_main.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc691f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|lenght|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "|  ham|I'm gonna be home...|   109|\n",
      "| spam|SIX chances to wi...|   136|\n",
      "| spam|URGENT! You have ...|   155|\n",
      "|  ham|I've been searchi...|   196|\n",
      "|  ham|I HAVE A DATE ON ...|    35|\n",
      "| spam|XXXMobileMovieClu...|   149|\n",
      "|  ham|Oh k...i'm watchi...|    26|\n",
      "|  ham|Eh u remember how...|    81|\n",
      "|  ham|Fine if thats th...|    56|\n",
      "| spam|England v Macedon...|   155|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the length function from pyspark.sql.functions\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "# Add a new column 'length' to the DataFrame 'data_main' containing the length of the 'text' column\n",
    "data_main = data_main.withColumn('lenght', length(data_main['text']))\n",
    "\n",
    "# Display the contents of the updated DataFrame 'data_main'\n",
    "data_main.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435d7d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(lenght)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group the DataFrame 'data_main' by the 'class' column and calculate the mean for each group\n",
    "# Then, display the resulting DataFrame\n",
    "data_main.groupBy('class').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f937fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+--------------------+\n",
      "|class|                text|lenght|               words|\n",
      "+-----+--------------------+------+--------------------+\n",
      "|  ham|Go until jurong p...|   111|[go, until, juron...|\n",
      "|  ham|Ok lar... Joking ...|    29|[ok, lar..., joki...|\n",
      "| spam|Free entry in 2 a...|   155|[free, entry, in,...|\n",
      "|  ham|U dun say so earl...|    49|[u, dun, say, so,...|\n",
      "|  ham|Nah I don't think...|    61|[nah, i, don't, t...|\n",
      "| spam|FreeMsg Hey there...|   147|[freemsg, hey, th...|\n",
      "|  ham|Even my brother i...|    77|[even, my, brothe...|\n",
      "|  ham|As per your reque...|   160|[as, per, your, r...|\n",
      "| spam|WINNER!! As a val...|   157|[winner!!, as, a,...|\n",
      "| spam|Had your mobile 1...|   154|[had, your, mobil...|\n",
      "|  ham|I'm gonna be home...|   109|[i'm, gonna, be, ...|\n",
      "| spam|SIX chances to wi...|   136|[six, chances, to...|\n",
      "| spam|URGENT! You have ...|   155|[urgent!, you, ha...|\n",
      "|  ham|I've been searchi...|   196|[i've, been, sear...|\n",
      "|  ham|I HAVE A DATE ON ...|    35|[i, have, a, date...|\n",
      "| spam|XXXMobileMovieClu...|   149|[xxxmobilemoviecl...|\n",
      "|  ham|Oh k...i'm watchi...|    26|[oh, k...i'm, wat...|\n",
      "|  ham|Eh u remember how...|    81|[eh, u, remember,...|\n",
      "|  ham|Fine if thats th...|    56|[fine, if, thats...|\n",
      "| spam|England v Macedon...|   155|[england, v, mace...|\n",
      "+-----+--------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary classes from pyspark.ml.feature\n",
    "from pyspark.ml.feature import (Tokenizer,StopWordsRemover,CountVectorizer, IDF,\n",
    "                                StringIndexer)\n",
    "\n",
    "# Create a Tokenizer object to tokenize the 'text' column and output the result to the 'words' column\n",
    "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
    "\n",
    "# Transform the DataFrame 'data_main' using the Tokenizer\n",
    "data_tokeniz = tokenizer.transform(data_main)\n",
    "\n",
    "# Display the DataFrame with the 'words' column containing tokenized text\n",
    "data_tokeniz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9954dd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+--------------------+------------+\n",
      "|class|                text|lenght|               words|lenght_words|\n",
      "+-----+--------------------+------+--------------------+------------+\n",
      "|  ham|Go until jurong p...|   111|[go, until, juron...|          20|\n",
      "|  ham|Ok lar... Joking ...|    29|[ok, lar..., joki...|           6|\n",
      "| spam|Free entry in 2 a...|   155|[free, entry, in,...|          28|\n",
      "|  ham|U dun say so earl...|    49|[u, dun, say, so,...|          11|\n",
      "|  ham|Nah I don't think...|    61|[nah, i, don't, t...|          13|\n",
      "| spam|FreeMsg Hey there...|   147|[freemsg, hey, th...|          32|\n",
      "|  ham|Even my brother i...|    77|[even, my, brothe...|          16|\n",
      "|  ham|As per your reque...|   160|[as, per, your, r...|          26|\n",
      "| spam|WINNER!! As a val...|   157|[winner!!, as, a,...|          26|\n",
      "| spam|Had your mobile 1...|   154|[had, your, mobil...|          29|\n",
      "|  ham|I'm gonna be home...|   109|[i'm, gonna, be, ...|          21|\n",
      "| spam|SIX chances to wi...|   136|[six, chances, to...|          26|\n",
      "| spam|URGENT! You have ...|   155|[urgent!, you, ha...|          26|\n",
      "|  ham|I've been searchi...|   196|[i've, been, sear...|          37|\n",
      "|  ham|I HAVE A DATE ON ...|    35|[i, have, a, date...|           8|\n",
      "| spam|XXXMobileMovieClu...|   149|[xxxmobilemoviecl...|          19|\n",
      "|  ham|Oh k...i'm watchi...|    26|[oh, k...i'm, wat...|           4|\n",
      "|  ham|Eh u remember how...|    81|[eh, u, remember,...|          19|\n",
      "|  ham|Fine if thats th...|    56|[fine, if, thats...|          13|\n",
      "| spam|England v Macedon...|   155|[england, v, mace...|          24|\n",
      "+-----+--------------------+------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import necessary functions and types from the PySpark SQL library\n",
    "from pyspark.sql.functions import col,udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Create a User Defined Function (UDF) to count the number of words in a column\n",
    "count_token = udf(lambda words:len(words), IntegerType())\n",
    "\n",
    "# Add a new column 'length_words' to the DataFrame 'data_tokeniz' using the UDF\n",
    "data_tokeniz.withColumn('lenght_words',count_token(col('words'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7145514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+--------------------+--------------------+\n",
      "|class|                text|lenght|               words|           StopWords|\n",
      "+-----+--------------------+------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|   111|[go, until, juron...|[go, jurong, poin...|\n",
      "|  ham|Ok lar... Joking ...|    29|[ok, lar..., joki...|[ok, lar..., joki...|\n",
      "| spam|Free entry in 2 a...|   155|[free, entry, in,...|[free, entry, 2, ...|\n",
      "|  ham|U dun say so earl...|    49|[u, dun, say, so,...|[u, dun, say, ear...|\n",
      "|  ham|Nah I don't think...|    61|[nah, i, don't, t...|[nah, think, goes...|\n",
      "| spam|FreeMsg Hey there...|   147|[freemsg, hey, th...|[freemsg, hey, da...|\n",
      "|  ham|Even my brother i...|    77|[even, my, brothe...|[even, brother, l...|\n",
      "|  ham|As per your reque...|   160|[as, per, your, r...|[per, request, 'm...|\n",
      "| spam|WINNER!! As a val...|   157|[winner!!, as, a,...|[winner!!, valued...|\n",
      "| spam|Had your mobile 1...|   154|[had, your, mobil...|[mobile, 11, mont...|\n",
      "|  ham|I'm gonna be home...|   109|[i'm, gonna, be, ...|[gonna, home, soo...|\n",
      "| spam|SIX chances to wi...|   136|[six, chances, to...|[six, chances, wi...|\n",
      "| spam|URGENT! You have ...|   155|[urgent!, you, ha...|[urgent!, won, 1,...|\n",
      "|  ham|I've been searchi...|   196|[i've, been, sear...|[searching, right...|\n",
      "|  ham|I HAVE A DATE ON ...|    35|[i, have, a, date...|[date, sunday, wi...|\n",
      "| spam|XXXMobileMovieClu...|   149|[xxxmobilemoviecl...|[xxxmobilemoviecl...|\n",
      "|  ham|Oh k...i'm watchi...|    26|[oh, k...i'm, wat...|[oh, k...i'm, wat...|\n",
      "|  ham|Eh u remember how...|    81|[eh, u, remember,...|[eh, u, remember,...|\n",
      "|  ham|Fine if thats th...|    56|[fine, if, thats...|[fine, thats, wa...|\n",
      "| spam|England v Macedon...|   155|[england, v, mace...|[england, v, mace...|\n",
      "+-----+--------------------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a StopWordsRemover object, specifying the input and output columns\n",
    "remover = StopWordsRemover(inputCol='words' , outputCol='StopWords')\n",
    "\n",
    "# Use the StopWordsRemover to transform the 'data_tokeniz' DataFrame and remove stop words\n",
    "remover_StopWord = remover.transform(data_tokeniz)\n",
    "\n",
    "# Show the resulting DataFrame after removing stop words\n",
    "remover_StopWord.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b409b027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+--------------------+--------------------+----------------+\n",
      "|class|                text|lenght|               words|           StopWords|lenght_StopWords|\n",
      "+-----+--------------------+------+--------------------+--------------------+----------------+\n",
      "|  ham|Go until jurong p...|   111|[go, until, juron...|[go, jurong, poin...|              16|\n",
      "|  ham|Ok lar... Joking ...|    29|[ok, lar..., joki...|[ok, lar..., joki...|               6|\n",
      "| spam|Free entry in 2 a...|   155|[free, entry, in,...|[free, entry, 2, ...|              23|\n",
      "|  ham|U dun say so earl...|    49|[u, dun, say, so,...|[u, dun, say, ear...|               9|\n",
      "|  ham|Nah I don't think...|    61|[nah, i, don't, t...|[nah, think, goes...|               7|\n",
      "| spam|FreeMsg Hey there...|   147|[freemsg, hey, th...|[freemsg, hey, da...|              18|\n",
      "|  ham|Even my brother i...|    77|[even, my, brothe...|[even, brother, l...|               9|\n",
      "|  ham|As per your reque...|   160|[as, per, your, r...|[per, request, 'm...|              16|\n",
      "| spam|WINNER!! As a val...|   157|[winner!!, as, a,...|[winner!!, valued...|              19|\n",
      "| spam|Had your mobile 1...|   154|[had, your, mobil...|[mobile, 11, mont...|              19|\n",
      "|  ham|I'm gonna be home...|   109|[i'm, gonna, be, ...|[gonna, home, soo...|              12|\n",
      "| spam|SIX chances to wi...|   136|[six, chances, to...|[six, chances, wi...|              21|\n",
      "| spam|URGENT! You have ...|   155|[urgent!, you, ha...|[urgent!, won, 1,...|              19|\n",
      "|  ham|I've been searchi...|   196|[i've, been, sear...|[searching, right...|              15|\n",
      "|  ham|I HAVE A DATE ON ...|    35|[i, have, a, date...|[date, sunday, wi...|               3|\n",
      "| spam|XXXMobileMovieClu...|   149|[xxxmobilemoviecl...|[xxxmobilemoviecl...|              13|\n",
      "|  ham|Oh k...i'm watchi...|    26|[oh, k...i'm, wat...|[oh, k...i'm, wat...|               4|\n",
      "|  ham|Eh u remember how...|    81|[eh, u, remember,...|[eh, u, remember,...|              13|\n",
      "|  ham|Fine if thats th...|    56|[fine, if, thats...|[fine, thats, wa...|               9|\n",
      "| spam|England v Macedon...|   155|[england, v, mace...|[england, v, mace...|              21|\n",
      "+-----+--------------------+------+--------------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a User Defined Function (UDF) to count the number of words in the 'StopWords' column\n",
    "count_token1 = udf(lambda StopWords:len(StopWords), IntegerType())\n",
    "\n",
    "# Add a new column 'lenght_StopWords' to the 'remover_StopWord' DataFrame using the UDF\n",
    "remover_StopWord.withColumn('lenght_StopWords',count_token1(col('StopWords'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82b5ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+--------------------+--------------------+--------------------+\n",
      "|class|                text|lenght|               words|           StopWords|               c_vec|\n",
      "+-----+--------------------+------+--------------------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|   111|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|\n",
      "|  ham|Ok lar... Joking ...|    29|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,301,...|\n",
      "| spam|Free entry in 2 a...|   155|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|\n",
      "|  ham|U dun say so earl...|    49|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|\n",
      "|  ham|Nah I don't think...|    61|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|\n",
      "| spam|FreeMsg Hey there...|   147|[freemsg, hey, th...|[freemsg, hey, da...|(13423,[10,60,140...|\n",
      "|  ham|Even my brother i...|    77|[even, my, brothe...|[even, brother, l...|(13423,[10,53,102...|\n",
      "|  ham|As per your reque...|   160|[as, per, your, r...|[per, request, 'm...|(13423,[127,185,4...|\n",
      "| spam|WINNER!! As a val...|   157|[winner!!, as, a,...|[winner!!, valued...|(13423,[1,47,121,...|\n",
      "| spam|Had your mobile 1...|   154|[had, your, mobil...|[mobile, 11, mont...|(13423,[0,1,13,27...|\n",
      "|  ham|I'm gonna be home...|   109|[i'm, gonna, be, ...|[gonna, home, soo...|(13423,[18,43,117...|\n",
      "| spam|SIX chances to wi...|   136|[six, chances, to...|[six, chances, wi...|(13423,[8,16,37,8...|\n",
      "| spam|URGENT! You have ...|   155|[urgent!, you, ha...|[urgent!, won, 1,...|(13423,[13,30,47,...|\n",
      "|  ham|I've been searchi...|   196|[i've, been, sear...|[searching, right...|(13423,[39,95,221...|\n",
      "|  ham|I HAVE A DATE ON ...|    35|[i, have, a, date...|[date, sunday, wi...|(13423,[555,1797,...|\n",
      "| spam|XXXMobileMovieClu...|   149|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(13423,[30,109,11...|\n",
      "|  ham|Oh k...i'm watchi...|    26|[oh, k...i'm, wat...|[oh, k...i'm, wat...|(13423,[82,214,44...|\n",
      "|  ham|Eh u remember how...|    81|[eh, u, remember,...|[eh, u, remember,...|(13423,[0,2,49,13...|\n",
      "|  ham|Fine if thats th...|    56|[fine, if, thats...|[fine, thats, wa...|(13423,[0,74,105,...|\n",
      "| spam|England v Macedon...|   155|[england, v, mace...|[england, v, mace...|(13423,[4,30,33,5...|\n",
      "+-----+--------------------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer object, specifying the input and output columns\n",
    "count_vc = CountVectorizer(inputCol='StopWords', outputCol='c_vec')\n",
    "\n",
    "# Fit the CountVectorizer model on the 'remover_StopWord' DataFrame\n",
    "model = count_vc.fit(remover_StopWord)\n",
    "\n",
    "# Transform the 'remover_StopWord' DataFrame using the fitted CountVectorizer model\n",
    "data_ConVec = model.transform(remover_StopWord)\n",
    "\n",
    "# Show the resulting DataFrame with the CountVectorizer output\n",
    "data_ConVec.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43346f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 idf|\n",
      "+--------------------+\n",
      "|(13423,[7,11,31,6...|\n",
      "|(13423,[0,24,301,...|\n",
      "|(13423,[2,13,19,3...|\n",
      "|(13423,[0,70,80,1...|\n",
      "|(13423,[36,134,31...|\n",
      "|(13423,[10,60,140...|\n",
      "|(13423,[10,53,102...|\n",
      "|(13423,[127,185,4...|\n",
      "|(13423,[1,47,121,...|\n",
      "|(13423,[0,1,13,27...|\n",
      "|(13423,[18,43,117...|\n",
      "|(13423,[8,16,37,8...|\n",
      "|(13423,[13,30,47,...|\n",
      "|(13423,[39,95,221...|\n",
      "|(13423,[555,1797,...|\n",
      "|(13423,[30,109,11...|\n",
      "|(13423,[82,214,44...|\n",
      "|(13423,[0,2,49,13...|\n",
      "|(13423,[0,74,105,...|\n",
      "|(13423,[4,30,33,5...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an IDF (Inverse Document Frequency) object, specifying the input and output columns\n",
    "idf = IDF(inputCol='c_vec', outputCol='idf')\n",
    "\n",
    "# Fit the IDF model on the 'data_ConVec' DataFrame\n",
    "idf_model = idf.fit(data_ConVec)\n",
    "\n",
    "# Transform the 'data_ConVec' DataFrame using the fitted IDF model\n",
    "data_idf = idf_model.transform(data_ConVec)\n",
    "\n",
    "# Select and display the 'idf' column from the resulting DataFrame\n",
    "data_idf.select('idf').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161e1545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                 idf|\n",
      "+-----+--------------------+\n",
      "|  0.0|(13423,[7,11,31,6...|\n",
      "|  0.0|(13423,[0,24,301,...|\n",
      "|  1.0|(13423,[2,13,19,3...|\n",
      "|  0.0|(13423,[0,70,80,1...|\n",
      "|  0.0|(13423,[36,134,31...|\n",
      "|  1.0|(13423,[10,60,140...|\n",
      "|  0.0|(13423,[10,53,102...|\n",
      "|  0.0|(13423,[127,185,4...|\n",
      "|  1.0|(13423,[1,47,121,...|\n",
      "|  1.0|(13423,[0,1,13,27...|\n",
      "|  0.0|(13423,[18,43,117...|\n",
      "|  1.0|(13423,[8,16,37,8...|\n",
      "|  1.0|(13423,[13,30,47,...|\n",
      "|  0.0|(13423,[39,95,221...|\n",
      "|  0.0|(13423,[555,1797,...|\n",
      "|  1.0|(13423,[30,109,11...|\n",
      "|  0.0|(13423,[82,214,44...|\n",
      "|  0.0|(13423,[0,2,49,13...|\n",
      "|  0.0|(13423,[0,74,105,...|\n",
      "|  1.0|(13423,[4,30,33,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a StringIndexer object, specifying the input and output columns\n",
    "hamOrSpam = StringIndexer(inputCol='class', outputCol='label')\n",
    "\n",
    "# Fit the StringIndexer model on the 'data_idf' DataFrame\n",
    "data_index_fit = hamOrSpam.fit(data_idf)\n",
    "\n",
    "# Transform the 'data_idf' DataFrame using the fitted StringIndexer model\n",
    "data_index_transform = data_index_fit.transform(data_idf)\n",
    "\n",
    "# Select and display the 'label' and 'idf' columns from the resulting DataFrame\n",
    "data_index_transform.select('label','idf').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e6266e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(13424,[7,11,31,6...|\n",
      "|(13424,[0,24,301,...|\n",
      "|(13424,[2,13,19,3...|\n",
      "|(13424,[0,70,80,1...|\n",
      "|(13424,[36,134,31...|\n",
      "|(13424,[10,60,140...|\n",
      "|(13424,[10,53,102...|\n",
      "|(13424,[127,185,4...|\n",
      "|(13424,[1,47,121,...|\n",
      "|(13424,[0,1,13,27...|\n",
      "|(13424,[18,43,117...|\n",
      "|(13424,[8,16,37,8...|\n",
      "|(13424,[13,30,47,...|\n",
      "|(13424,[39,95,221...|\n",
      "|(13424,[555,1797,...|\n",
      "|(13424,[30,109,11...|\n",
      "|(13424,[82,214,44...|\n",
      "|(13424,[0,2,49,13...|\n",
      "|(13424,[0,74,105,...|\n",
      "|(13424,[4,30,33,5...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the VectorAssembler from PySpark ML\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create a VectorAssembler object, specifying the input columns and the output column\n",
    "vector = VectorAssembler(inputCols=['idf','lenght'] , outputCol='features')\n",
    "\n",
    "# Transform the 'data_index_transform' DataFrame using the VectorAssembler\n",
    "data_vector = vector.transform(data_index_transform)\n",
    "\n",
    "# Select and display the 'features' column from the resulting DataFrame\n",
    "data_vector.select('features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e7a9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/18 10:32:39 WARN DAGScheduler: Broadcasting large task binary with size 1149.8 KiB\n",
      "23/09/18 10:32:40 WARN DAGScheduler: Broadcasting large task binary with size 1109.1 KiB\n",
      "23/09/18 10:32:40 WARN DAGScheduler: Broadcasting large task binary with size 1369.2 KiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|class|                text|lenght|               words|           StopWords|               c_vec|                 idf|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  ham| &lt;#&gt;  mins ...|    51|[, &lt;#&gt;, , m...|[, &lt;#&gt;, , m...|(13423,[3,6,41,20...|(13423,[3,6,41,20...|  0.0|(13424,[3,6,41,20...|[-296.21333971150...|[1.0,3.9256758039...|       0.0|\n",
      "|  ham| &lt;DECIMAL&gt; ...|   132|[, &lt;decimal&gt...|[, &lt;decimal&gt...|(13423,[3,84,115,...|(13423,[3,84,115,...|  0.0|(13424,[3,84,115,...|[-875.39176509594...|[1.0,8.9058032888...|       0.0|\n",
      "|  ham| said kiss, kiss,...|   133|[, said, kiss,, k...|[, said, kiss,, k...|(13423,[3,92,215,...|(13423,[3,92,215,...|  0.0|(13424,[3,92,215,...|[-1077.4554351260...|[1.0,2.6183289943...|       0.0|\n",
      "|  ham| what number do u...|    36|[, what, number, ...|[, number, u, liv...|(13423,[0,3,88,18...|(13423,[0,3,88,18...|  0.0|(13424,[0,3,88,18...|[-310.39383219069...|[0.99999907031445...|       0.0|\n",
      "|  ham|\"The world suffer...|   129|[\"the, world, suf...|[\"the, world, suf...|(13423,[15,112,31...|(13423,[15,112,31...|  0.0|(13424,[15,112,31...|[-936.43567374402...|[1.0,3.0194584286...|       0.0|\n",
      "|  ham|&lt;#&gt;  is fas...|   461|[&lt;#&gt;, , is,...|[&lt;#&gt;, , fas...|(13423,[0,3,6,8,1...|(13423,[0,3,6,8,1...|  0.0|(13424,[0,3,6,8,1...|[-3615.1304175908...|[1.0,4.5797247038...|       0.0|\n",
      "|  ham|&lt;#&gt;  w jett...|    37|[&lt;#&gt;, , w, ...|[&lt;#&gt;, , w, ...|(13423,[3,6,296,6...|(13423,[3,6,296,6...|  0.0|(13424,[3,6,296,6...|[-327.79751658640...|[1.0,2.3548721128...|       0.0|\n",
      "|  ham|&lt;#&gt; , that'...|    48|[&lt;#&gt;, ,, th...|[&lt;#&gt;, ,, al...|(13423,[6,212,249...|(13423,[6,212,249...|  0.0|(13424,[6,212,249...|[-312.76211020253...|[1.0,1.3694941907...|       0.0|\n",
      "|  ham|(And my man carlo...|    66|[(and, my, man, c...|[(and, man, carlo...|(13423,[163,242,6...|(13423,[163,242,6...|  0.0|(13424,[163,242,6...|[-593.36248641483...|[1.0,2.0599779351...|       0.0|\n",
      "|  ham|(That said can yo...|    43|[(that, said, can...|[(that, said, tex...|(13423,[19,29,92,...|(13423,[19,29,92,...|  0.0|(13424,[19,29,92,...|[-318.17418590521...|[0.99959616725157...|       0.0|\n",
      "|  ham|* Thought I didn'...|    27|[*, thought, i, d...|[*, thought, see,...|(13423,[32,66,168...|(13423,[32,66,168...|  0.0|(13424,[32,66,168...|[-153.99781423743...|[0.99999999999999...|       0.0|\n",
      "|  ham|* You gonna ring ...|    37|[*, you, gonna, r...|[*, gonna, ring, ...|(13423,[117,192,4...|(13423,[117,192,4...|  0.0|(13424,[117,192,4...|[-308.64280246425...|[0.99999999398070...|       0.0|\n",
      "|  ham|... Are you in th...|    23|[..., are, you, i...|         [..., pub?]|(13423,[22,4427],...|(13423,[22,4427],...|  0.0|(13424,[22,4427,1...|[-138.26705361751...|[0.99999982116593...|       0.0|\n",
      "|  ham|.Please charge my...|    52|[.please, charge,...|[.please, charge,...|(13423,[5,38,575,...|(13423,[5,38,575,...|  0.0|(13424,[5,38,575,...|[-299.36812859749...|[0.96849301264450...|       0.0|\n",
      "|  ham|1's reach home ca...|    23|[1's, reach, home...|[1's, reach, home...|(13423,[1,43,53,2...|(13423,[1,43,53,2...|  0.0|(13424,[1,43,53,2...|[-213.05397802421...|[0.99999999999975...|       0.0|\n",
      "|  ham|1) Go to write ms...|   141|[1), go, to, writ...|[1), go, write, m...|(13423,[3,4,6,7,9...|(13423,[3,4,6,7,9...|  0.0|(13424,[3,4,6,7,9...|[-1171.9147372987...|[1.0,7.3231663880...|       0.0|\n",
      "|  ham|1.20 that call co...|    79|[1.20, that, call...|[1.20, call, cost...|(13423,[1,18,21,2...|(13423,[1,18,21,2...|  0.0|(13424,[1,18,21,2...|[-778.31596885105...|[1.0,3.2910023423...|       0.0|\n",
      "|  ham|   10 min later k...|    17|[10, min, later, ...|[10, min, later, ...|(13423,[56,356,62...|(13423,[56,356,62...|  0.0|(13424,[56,356,62...|[-215.60423061446...|[0.99999999986591...|       0.0|\n",
      "|  ham|1Apple/Day=No Doc...|   154|[1apple/day=no, d...|[1apple/day=no, d...|(13423,[0,2,140,1...|(13423,[0,2,140,1...|  0.0|(13424,[0,2,140,1...|[-1806.1442230748...|[3.00972435930970...|       1.0|\n",
      "|  ham|4 oclock at mine....|    47|[4, oclock, at, m...|[4, oclock, mine....|(13423,[8,2557,27...|(13423,[8,2557,27...|  0.0|(13424,[8,2557,27...|[-487.48978057103...|[0.99999784646683...|       0.0|\n",
      "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/18 10:32:40 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "# Split the 'data_vector' DataFrame into training (70%) and testing (30%) datasets\n",
    "train , test = data_vector.randomSplit([0.7,0.3])\n",
    "\n",
    "# Import the NaiveBayes classifier from PySpark ML\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "# Create a NaiveBayes model\n",
    "model = NaiveBayes()\n",
    "\n",
    "# Fit the NaiveBayes model on the training data\n",
    "model_fit = model.fit(train)\n",
    "\n",
    "# Make predictions on the test data using the fitted model\n",
    "test_result = model_fit.transform(test)\n",
    "\n",
    "# Show the results of the predictions\n",
    "test_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b249a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/18 10:32:40 WARN DAGScheduler: Broadcasting large task binary with size 1359.7 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9263965631920426"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the MulticlassClassificationEvaluator from PySpark ML\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Create a MulticlassClassificationEvaluator object\n",
    "evaluator_model = MulticlassClassificationEvaluator()\n",
    "\n",
    "# Evaluate the model's performance on the test data and calculate the accuracy\n",
    "acc = evaluator_model.evaluate(test_result)\n",
    "\n",
    "# Display the accuracy\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea3a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
